{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIST 664\\nHomework 1\\nSammy Pardes\\n1/28/21\\n\\ndata source: https://www.kaggle.com/tunguz/200000-jeopardy-questions \\n\\nadditionals sources:\\nhttps://pbpython.com/currency-cleanup.html\\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html\\nhttps://pbpython.com/currency-cleanup.html\\nhttps://www.geeksforgeeks.org/selecting-rows-in-pandas-dataframe-based-on-conditions/\\nhttps://stackoverflow.com/questions/8478602/convert-a-list-of-string-sentences-to-words\\nhttps://stackoverflow.com/questions/45516207/removing-stop-words-and-string-punctuation\\nhttps://stackoverflow.com/questions/38597503/in-nltk-get-the-number-of-occurrences-of-a-trigram\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "IST 664\n",
    "Homework 1\n",
    "Sammy Pardes\n",
    "1/28/21\n",
    "\n",
    "data source: https://www.kaggle.com/tunguz/200000-jeopardy-questions \n",
    "\n",
    "additionals sources:\n",
    "https://pbpython.com/currency-cleanup.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html\n",
    "https://pbpython.com/currency-cleanup.html\n",
    "https://www.geeksforgeeks.org/selecting-rows-in-pandas-dataframe-based-on-conditions/\n",
    "https://stackoverflow.com/questions/8478602/convert-a-list-of-string-sentences-to-words\n",
    "https://stackoverflow.com/questions/45516207/removing-stop-words-and-string-punctuation\n",
    "https://stackoverflow.com/questions/38597503/in-nltk-get-the-number-of-occurrences-of-a-trigram\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\slpar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import statements\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "nltk.download(\"stopwords\")\n",
    "import string\n",
    "from nltk.collocations import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data and preview first few rows\n",
    "jeopardy = pd.read_csv(\"JEOPARDY_CSV.csv\")\n",
    "\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_number</th>\n",
       "      <th>air_date</th>\n",
       "      <th>round</th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   show_number    air_date      round                         category value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            question      answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns to remove extra spaces\n",
    "\n",
    "#create list of new column names\n",
    "columns = [\"show_number\", \"air_date\", \"round\", \"category\", \"value\", \"question\", \"answer\"]\n",
    "\n",
    "#overwrite column names with values in the columns list\n",
    "jeopardy.columns = columns\n",
    "\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$200', '$400', '$600', '$800', '$2,000', '$1000', '$1200', '$1600', '$2000', '$3,200', 'None', '$5,000', '$100', '$300', '$500', '$1,000', '$1,500', '$1,200', '$4,800', '$1,800', '$1,100', '$2,200', '$3,400', '$3,000', '$4,000', '$1,600', '$6,800', '$1,900', '$3,100', '$700', '$1,400', '$2,800', '$8,000', '$6,000', '$2,400', '$12,000', '$3,800', '$2,500', '$6,200', '$10,000', '$7,000', '$1,492', '$7,400', '$1,300', '$7,200', '$2,600', '$3,300', '$5,400', '$4,500', '$2,100', '$900', '$3,600', '$2,127', '$367', '$4,400', '$3,500', '$2,900', '$3,900', '$4,100', '$4,600', '$10,800', '$2,300', '$5,600', '$1,111', '$8,200', '$5,800', '$750', '$7,500', '$1,700', '$9,000', '$6,100', '$1,020', '$4,700', '$2,021', '$5,200', '$3,389', '$4,200', '$5', '$2,001', '$1,263', '$4,637', '$3,201', '$6,600', '$3,700', '$2,990', '$5,500', '$14,000', '$2,700', '$6,400', '$350', '$8,600', '$6,300', '$250', '$3,989', '$8,917', '$9,500', '$1,246', '$6,435', '$8,800', '$2,222', '$2,746', '$10,400', '$7,600', '$6,700', '$5,100', '$13,200', '$4,300', '$1,407', '$12,400', '$5,401', '$7,800', '$1,183', '$1,203', '$13,000', '$11,600', '$14,200', '$1,809', '$8,400', '$8,700', '$11,000', '$5,201', '$1,801', '$3,499', '$5,700', '$601', '$4,008', '$50', '$2,344', '$2,811', '$18,000', '$1,777', '$3,599', '$9,800', '$796', '$3,150', '$20', '$1,810', '$22', '$9,200', '$1,512', '$8,500', '$585', '$1,534', '$13,800', '$5,001', '$4,238', '$16,400', '$1,347', '$2547', '$11,200']\n"
     ]
    }
   ],
   "source": [
    "#determine unique question values in data set\n",
    "\n",
    "#initialize empty list\n",
    "values = []\n",
    "\n",
    "#add unqiue values only to the values list\n",
    "for value in jeopardy[\"value\"]:\n",
    "    if value not in values:\n",
    "        values.append(value)\n",
    "        \n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    200\n",
       "1    200\n",
       "2    200\n",
       "3    200\n",
       "4    200\n",
       "Name: value, dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean up value column \n",
    "\n",
    "#remove questions where the Value is \"None\" and convert values to numbers\n",
    "jeopardy = jeopardy[jeopardy.value != \"None\"]\n",
    "\n",
    "#remove \"$\" and \",\" from values\n",
    "jeopardy[\"value\"] = jeopardy[\"value\"].str.replace(\"$\", \"\")\n",
    "jeopardy[\"value\"] = jeopardy[\"value\"].str.replace(\",\", \"\")\n",
    "\n",
    "#convert from string type to float type\n",
    "jeopardy[\"value\"] = jeopardy[\"value\"].astype(\"int\")\n",
    "\n",
    "jeopardy[\"value\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       show_number    air_date             round         category  value  \\\n",
      "20789          496  1986-11-03         Jeopardy!     LEAD SINGERS      5   \n",
      "39193          838  1988-04-06  Double Jeopardy!          \"WATER\"      5   \n",
      "47067         1194  1989-11-09         Jeopardy!  NAME'S THE SAME      5   \n",
      "53179         4813  2005-07-06  Double Jeopardy!             ANTS      5   \n",
      "75426         4643  2004-11-10  Double Jeopardy!           TRAVEL      5   \n",
      "\n",
      "                                                question  \\\n",
      "20789  [Audio] Called \"Buffoons of '60s British Rock ...   \n",
      "39193  It's reported the Rolling Stones took their na...   \n",
      "47067  John Dos Passos work, or the group heard <a hr...   \n",
      "53179  These insects also known as plant lice are cap...   \n",
      "75426  The Peer Gynt ski area has been called this co...   \n",
      "\n",
      "                         answer  \n",
      "20789  Freddie And The Dreamers  \n",
      "39193              Muddy Waters  \n",
      "47067        Manhattan Transfer  \n",
      "53179                    aphids  \n",
      "75426                    Norway  \n",
      "        show_number    air_date             round                 category  \\\n",
      "150825         6246  2011-11-14  Double Jeopardy!                LANGUAGES   \n",
      "195755         6217  2011-10-04  Double Jeopardy!                   PLUS 8   \n",
      "88937          6221  2011-10-10  Double Jeopardy!              \"A\" IN MATH   \n",
      "32508          4140  2002-09-06  Double Jeopardy!        SAINTS ON THE MAP   \n",
      "188391         5839  2010-01-21  Double Jeopardy!  REMEMBERING TED KENNEDY   \n",
      "\n",
      "        value                                           question        answer  \n",
      "150825  18000  Although Dutch is the official language, Srana...      Suriname  \n",
      "195755  16400       Number of days in a leap year times 2 plus 8           740  \n",
      "88937   14200  It's the length from the base of a cone to the...  the altitude  \n",
      "32508   14000  Jesse James was terminated in this city, once ...    St. Joseph  \n",
      "188391  13800  Kennedy called this the cause of his life & wa...   health care  \n"
     ]
    }
   ],
   "source": [
    "#create two data sets: lowest and highest value questions\n",
    "numquestions = 20000\n",
    "\n",
    "jeopardylow = jeopardy.nsmallest(numquestions, \"value\")\n",
    "\n",
    "jeopardyhigh = jeopardy.nlargest(numquestions, \"value\")\n",
    "\n",
    "print(jeopardylow.head())\n",
    "print(jeopardyhigh.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20789    [audio] called \"buffoons of '60s british rock ...\n",
      "39193    it's reported the rolling stones took their na...\n",
      "47067    john dos passos work, or the group heard <a hr...\n",
      "53179    these insects also known as plant lice are cap...\n",
      "75426    the peer gynt ski area has been called this co...\n",
      "Name: question, dtype: object\n",
      "150825    although dutch is the official language, srana...\n",
      "195755         number of days in a leap year times 2 plus 8\n",
      "88937     it's the length from the base of a cone to the...\n",
      "32508     jesse james was terminated in this city, once ...\n",
      "188391    kennedy called this the cause of his life & wa...\n",
      "Name: question, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#get questions only from high/low lists and convert to lowercase\n",
    "jeopardylowqs = jeopardylow[\"question\"].str.lower()\n",
    "jeopardyhighqs = jeopardyhigh[\"question\"].str.lower()\n",
    "\n",
    "print(jeopardylowqs.head())\n",
    "print(jeopardyhighqs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jeopardylowqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-41c4237f7f57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#if the word in any question appears in the regex patter, append to html list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjeopardylowqs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquestion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jeopardylowqs' is not defined"
     ]
    }
   ],
   "source": [
    "#tokenize, remove stopwords, remove punctuation, remove HTML\n",
    "\n",
    "#use regex to clean out HTML\n",
    "#initialize empty list\n",
    "html = []\n",
    "\n",
    "#define HTML tag pattern with regex\n",
    "pattern = '<.*[\\s]?/?.*>?|target=\"_blank\">.*\\.?'\n",
    "\n",
    "#if the word in any question appears in the regex patter, append to html list\n",
    "for question in jeopardylowqs:\n",
    "    for word in question.split(' '):\n",
    "        if nltk.regexp_tokenize(word, pattern):\n",
    "            html.append(word)\n",
    "            \n",
    "for question in jeopardyhighqs:\n",
    "    for word in question.split(' '):\n",
    "        if nltk.regexp_tokenize(word, pattern):\n",
    "            html.append(word)\n",
    "\n",
    "print(len(html), '\\n')\n",
    "print(html[:100])\n",
    "\n",
    "#define stopwords\n",
    "mystop = ['clue', 'crew', 'like', '\"it\\'ll', '\"the', 'this,', 'also', 'may', '1', '2', '3']\n",
    "\n",
    "#get stopwords from nltk and add additional words\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords = stopwords + mystop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[audio]', 'called', '\"buffoons', \"'60s\", 'british', 'rock', 'invasion\",', 'led', 'ex-milkman', 'named', 'garrity:', 'reported', 'rolling', 'stones', 'took', 'name', 'following', 'blues', 'song', 'singer:', 'john', 'dos', 'passos', 'work,', 'group', 'heard', 'wah', 'ooh', 'wah', 'cool', 'cool', 'kitty', 'asks', 'boy', 'new', 'york', 'insects', 'known', 'plant', 'lice', 'captured', '\"milked\"', 'many', 'ants', 'honeydew', 'liquid', 'produce', 'peer', 'gynt', 'ski', 'area', 'called', \"country's\", 'best', 'place', 'cross-country', 'skiing', 'latin', '\"to', 'correct\",', 'adjective', 'someone', \"can't\", 'corrected', 'reformed', '(jimmy', 'carnegie', 'mellon', 'university', 'pittsburgh)', 'greek', '\"self-acting\",', 'another', 'word', 'robot', 'mimics', 'human', 'actions', 'master', 'craftsman,', 'invented', 'axe', 'built', 'labyrinth', '1964', 'elvis', 'bought', 'yacht', 'owned', 'ex-president', '$55,000,', 'donated', 'march', 'dimes', 'john', 'howard', 'griffin', 'chemically', 'darkened', 'skin']\n",
      "['although', 'dutch', 'official', 'language,', 'sranan', 'tongo', 'spoken', 'people', 'south', 'american', 'country', 'number', 'days', 'leap', 'year', 'times', 'plus', '8', 'length', 'base', 'cone', 'apex', 'jesse', 'james', 'terminated', 'city,', 'home', 'terminus', 'pony', 'express', 'kennedy', 'called', 'cause', 'life', 'hoping', 'see', 'reform', 'bill', 'passed', 'died', 'english', 'means', '\"truthful\";', 'german', '\"frenchman\"', 'tiller', 'engine,', 'start\"', 'receiving', '\"rock', 'solid\"', 'education', 'stanford,', 'lou', 'hoover', 'first', 'woman', 'earn', 'degree', 'aconcagua', 'one', 'alliteratively', 'known', '\"7\"', 'pd:', 'great', 'place', 'live', 'music', 'small', 'masses', 'lymphoid', 'tissue', 'nasopharynx', 'film', 'title', '\"eternal', 'sunshine', 'spotless', 'mind\"', 'comes', 'poem', 'ill-fated', 'medieval', 'lovers', 'annual', 'fishing', 'derby', 'fish', 'features', 'one', 'tagged', 'specimen', 'worth', '$100,000', 'africa', 'asia', 'joined', 'isthmus', 'separates']\n"
     ]
    }
   ],
   "source": [
    "#split questions on whitespace to get tokenized words\n",
    "#put in list if not a stopword and not punctuation\n",
    "\n",
    "#initialize empty token lists\n",
    "lowtokens = []\n",
    "hightokens = []\n",
    "\n",
    "#for each question, split on white space, add to token list if not stopword, punctuation, or html \n",
    "for question in jeopardylowqs:\n",
    "    for word in question.split(' '):\n",
    "        if word not in stopwords and word not in string.punctuation and word not in html:\n",
    "            lowtokens.append(word)\n",
    "        \n",
    "for question in jeopardyhighqs:\n",
    "    for word in question.split(' '):\n",
    "        if word not in stopwords and word not in string.punctuation and word not in html:\n",
    "            hightokens.append(word)\n",
    "\n",
    "print(lowtokens[:100])\n",
    "print(hightokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 Unigrams for Low-Value Questions\n",
      "\n",
      "one 0.007513674129871113\n",
      "first 0.006195153648642681\n",
      "name 0.004624284749954262\n",
      "city 0.0034256297670193234\n",
      "called 0.0029777113260278467\n",
      "u.s. 0.0029209329320993497\n",
      "new 0.002681201935512362\n",
      "state 0.0025297928850363696\n",
      "made 0.002466705780671373\n",
      "named 0.0024603970702348735\n",
      "country 0.0023973099658698765\n",
      "type 0.0023783838345603774\n",
      "film 0.0021449615484098895\n",
      "seen 0.00213865283797339\n",
      "used 0.0020440221814258946\n",
      "man 0.001924156683132401\n",
      "known 0.0018989218413864022\n",
      "became 0.0018547608683309046\n",
      "played 0.001709660528291412\n",
      "capital 0.001709660528291412\n",
      "title 0.001690734396981913\n",
      "years 0.0015897950299979182\n",
      "president 0.001570868898688419\n",
      "part 0.001495164373450423\n",
      "john 0.00135637274384743\n",
      "term 0.0013437553229744307\n",
      "famous 0.0013248291916649318\n",
      "word 0.0012869769290459337\n",
      "said 0.0012680507977364348\n",
      "people 0.001261742087299935\n",
      "home 0.0012554333768634355\n",
      "book 0.0012491246664269357\n",
      "largest 0.001242815955990436\n",
      "world 0.0012365072455539363\n",
      "born 0.001204963693371438\n",
      "last 0.0011923462724984387\n",
      "hit 0.0011797288516254393\n",
      "show 0.0011797288516254393\n",
      "american 0.0011797288516254393\n",
      "make 0.0011734201411889396\n",
      "war 0.0011481852994429408\n",
      "many 0.0011355678785699415\n",
      "get 0.0011229504576969421\n",
      "tv 0.0011040243263874432\n",
      "day 0.001085098195077944\n",
      "national 0.001085098195077944\n",
      "time 0.0010787894846414445\n",
      "song 0.0010409372220224465\n",
      "found 0.0010409372220224465\n",
      "island 0.0010220110907129473\n"
     ]
    }
   ],
   "source": [
    "#list the top 50 low value words by frequency (normalized by the length of the document)\n",
    "\n",
    "#get number of words in each list\n",
    "lowlen = len(lowtokens)\n",
    "highlen = len(hightokens)\n",
    "\n",
    "#get frequency distribution\n",
    "lowdist = nltk.FreqDist(lowtokens)\n",
    "lowdist\n",
    "\n",
    "#get normalized frequencies\n",
    "print(\"Top 50 Unigrams for Low-Value Questions\\n\")\n",
    "for word, freq in lowdist.most_common(50):\n",
    "    print(word, freq/lowlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 0.006952940329821803\n",
      "one 0.005535780517374047\n",
      "first 0.005054167612362505\n",
      "called 0.0033048609688723063\n",
      "named 0.00328271784680281\n",
      "seen 0.0029948572598993595\n",
      "title 0.0027457471366175274\n",
      "type 0.002695925111961161\n",
      "city 0.0026461030873047944\n",
      "new 0.002568602160061558\n",
      "known 0.0024523507691967027\n",
      "used 0.0024246718666098327\n",
      "word 0.002341635158849222\n",
      "u.s. 0.00214788284074113\n",
      "film 0.0020980608160847637\n",
      "made 0.001976273644702535\n",
      "state 0.0019652020836677868\n",
      "country 0.0019541305226330385\n",
      "man 0.0019264516200461683\n",
      "french 0.0018434149122855577\n",
      "novel 0.0017880571071118173\n",
      "last 0.0017382350824554508\n",
      "wrote 0.0016551983746948401\n",
      "became 0.0016330552526253438\n",
      "term 0.0016109121305558478\n",
      "part 0.0015832332279689775\n",
      "means 0.0015500185448647332\n",
      "american 0.0015168038617604889\n",
      "capital 0.0014448387150346263\n",
      "greek 0.001417159812447756\n",
      "president 0.0013894809098608859\n",
      "latin 0.0013784093488261378\n",
      "years 0.0013728735683087637\n",
      "island 0.0013009084215829011\n",
      "british 0.001273229518996031\n",
      "played 0.0012621579579612826\n",
      "war 0.0012566221774439087\n",
      "play 0.0012510863969265346\n",
      "work 0.0012510863969265346\n",
      "king 0.0012455506164091607\n",
      "whose 0.0012400148358917866\n",
      "famous 0.0012400148358917866\n",
      "south 0.0012289432748570385\n",
      "reports 0.0012234074943396644\n",
      "century 0.0012123359333049164\n",
      "said 0.0012012643722701683\n",
      "get 0.0012012643722701683\n",
      "john 0.0011846570307180461\n",
      "meaning 0.0011846570307180461\n",
      "book 0.0011403707865790538\n"
     ]
    }
   ],
   "source": [
    "#list the top 50 high value words by frequency (normalized by the length of the document)\n",
    "\n",
    "#get frequency distribution\n",
    "highdist = nltk.FreqDist(hightokens)\n",
    "\n",
    "#get normalized frequencies\n",
    "for word, freq in highdist.most_common(50):\n",
    "    print(word, freq/highlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('new', 'york'), 0.0006750320167054652)\n",
      "(('became', 'first'), 0.0005930187810309695)\n",
      "(('one', 'these,'), 0.00029020068007898505)\n",
      "(('last', 'name'), 0.0002838919696424854)\n",
      "(('capital', 'city'), 0.000233422286150488)\n",
      "(('seen', 'here,'), 0.0002081874444044893)\n",
      "(('prime', 'minister'), 0.00019557002353148993)\n",
      "(('whose', 'name'), 0.00019557002353148993)\n",
      "(('first', 'lady'), 0.00018926131309499026)\n",
      "(('19th', 'century'), 0.00018295260265849058)\n",
      "(('civil', 'war'), 0.00018295260265849058)\n",
      "(('first', 'name'), 0.00018295260265849058)\n",
      "(('title', 'character'), 0.0001766438922219909)\n",
      "(('york', 'city'), 0.00017033518178549123)\n",
      "(('tv', 'show'), 0.00016402647134899155)\n",
      "(('white', 'house'), 0.0001514090504759922)\n",
      "(('world', 'war'), 0.00014510034003949252)\n",
      "((\"world's\", 'largest'), 0.00014510034003949252)\n",
      "(('became', '1st'), 0.00013879162960299285)\n",
      "(('first', 'woman'), 0.00013879162960299285)\n",
      "(('hall', 'fame'), 0.00013879162960299285)\n",
      "(('national', 'park'), 0.00013879162960299285)\n",
      "(('shares', 'name'), 0.00013879162960299285)\n",
      "(('name', 'means'), 0.00013248291916649317)\n",
      "(('san', 'francisco'), 0.00013248291916649317)\n",
      "(('seen', 'here:'), 0.00013248291916649317)\n",
      "(('u.s.', 'president'), 0.00013248291916649317)\n",
      "(('years', 'later'), 0.00013248291916649317)\n",
      "(('could', 'tell'), 0.0001261742087299935)\n",
      "(('first', 'u.s.'), 0.0001261742087299935)\n",
      "(('ice', 'cream'), 0.0001261742087299935)\n",
      "(('new', 'jersey'), 0.0001261742087299935)\n",
      "(('years', 'ago'), 0.0001261742087299935)\n",
      "(('better', 'known'), 0.00011986549829349382)\n",
      "(('gave', 'us'), 0.00011986549829349382)\n",
      "(('high', 'school'), 0.00011986549829349382)\n",
      "(('united', 'states'), 0.00011986549829349382)\n",
      "(('said,', '\"i'), 0.00011355678785699416)\n",
      "(('body', 'part'), 0.00010724807742049448)\n",
      "(('first', 'time'), 0.00010724807742049448)\n",
      "(('largest', 'city'), 0.00010724807742049448)\n",
      "(('made', 'first'), 0.00010724807742049448)\n",
      "(('no.', 'hit'), 0.00010724807742049448)\n",
      "(('south', 'american'), 0.00010724807742049448)\n",
      "(('state', 'capital'), 0.00010724807742049448)\n",
      "(('washington,', 'd.c.'), 0.00010724807742049448)\n",
      "(('best', 'known'), 0.0001009393669839948)\n",
      "(('north', 'american'), 0.0001009393669839948)\n",
      "(('theme', 'song'), 0.0001009393669839948)\n",
      "(('used', 'make'), 0.0001009393669839948)\n"
     ]
    }
   ],
   "source": [
    "#list the top 50 low-value bigrams by frequencies\n",
    "\n",
    "#create shorthand for full measures function\n",
    "bgmeasures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "qfinderlow = BigramCollocationFinder.from_words(lowtokens)\n",
    "qscoredlow = qfinderlow.score_ngrams(bgmeasures.raw_freq)\n",
    "\n",
    "for bigram in qscoredlow[:50]:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('new', 'york'), 0.0005535780517374047)\n",
      "(('last', 'name'), 0.0004594697829420459)\n",
      "(('whose', 'name'), 0.00044286244138992377)\n",
      "(('became', 'first'), 0.0003985761972509314)\n",
      "(('19th', 'century'), 0.0003930404167335573)\n",
      "(('title', 'character'), 0.00028786058690345045)\n",
      "(('first', 'name'), 0.00027678902586870236)\n",
      "(('prime', 'minister'), 0.00027678902586870236)\n",
      "(('shares', 'name'), 0.00024357434276445808)\n",
      "(('south', 'american'), 0.00023803856224708403)\n",
      "(('world', 'war'), 0.00023803856224708403)\n",
      "(('name', 'means'), 0.00022143122069496189)\n",
      "(('word', 'meaning'), 0.00022143122069496189)\n",
      "(('nobel', 'prize'), 0.00019375231810809165)\n",
      "(('daily', 'double):'), 0.00018268075707334356)\n",
      "(('comes', 'latin'), 0.0001771449765559695)\n",
      "(('one', 'these,'), 0.0001771449765559695)\n",
      "(('supreme', 'court'), 0.0001771449765559695)\n",
      "(('seen', 'here,'), 0.00017160919603859546)\n",
      "(('african', 'country'), 0.00016607341552122141)\n",
      "(('best', 'known'), 0.00016053763500384737)\n",
      "(('gave', 'us'), 0.00015500185448647332)\n",
      "(('national', 'park'), 0.00015500185448647332)\n",
      "(('20th', 'century'), 0.00014393029345172523)\n",
      "(('capital', 'city'), 0.00013839451293435118)\n",
      "(('new', 'jersey'), 0.00013839451293435118)\n",
      "(('united', 'states'), 0.00013839451293435118)\n",
      "(('latin', '\"to'), 0.00013285873241697713)\n",
      "(('name', 'greek'), 0.00013285873241697713)\n",
      "(('civil', 'war'), 0.00012732295189960308)\n",
      "(('first', 'woman'), 0.00012732295189960308)\n",
      "(('hall', 'fame'), 0.00012732295189960308)\n",
      "(('white', 'house'), 0.00012732295189960308)\n",
      "(('(video', 'daily'), 0.00012178717138222904)\n",
      "(('body', 'water'), 0.00012178717138222904)\n",
      "(('name', 'comes'), 0.00012178717138222904)\n",
      "(('takes', 'place'), 0.00012178717138222904)\n",
      "(('word', 'means'), 0.00012178717138222904)\n",
      "(('work', 'seen'), 0.00012178717138222904)\n",
      "(('bears', 'name'), 0.00011625139086485499)\n",
      "(('comes', 'greek'), 0.00011625139086485499)\n",
      "(('north', 'carolina'), 0.00011625139086485499)\n",
      "(('secretary', 'state'), 0.00011625139086485499)\n",
      "(('shows', 'map'), 0.00011625139086485499)\n",
      "(('used', 'make'), 0.00011625139086485499)\n",
      "(('17th', 'century'), 0.00011071561034748094)\n",
      "(('often', 'used'), 0.00011071561034748094)\n",
      "(('state', 'university'), 0.00011071561034748094)\n",
      "(('washington,', 'd.c.'), 0.00011071561034748094)\n",
      "(('high', 'school'), 0.0001051798298301069)\n"
     ]
    }
   ],
   "source": [
    "#list the top 50 high-value bigrams by frequencies\n",
    "qfinderhigh = BigramCollocationFinder.from_words(hightokens)\n",
    "qscoredhigh = qfinderhigh.score_ngrams(bgmeasures.raw_freq)\n",
    "\n",
    "for bigram in qscoredhigh[:50]:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('\"annie', 'hall\"'), 14.95229534038602)\n",
      "(('\"robinson', 'crusoe\"'), 14.95229534038602)\n",
      "(('\"moby', 'dick\"'), 14.689260934552223)\n",
      "(('\"wheel', 'fortune\"'), 14.466868513215775)\n",
      "(('barbra', 'streisand'), 14.466868513215775)\n",
      "(('mick', 'jagger'), 14.466868513215775)\n",
      "(('orson', 'welles'), 14.274223435273381)\n",
      "(('potent', 'potable'), 14.203834107381983)\n",
      "(('da', 'vinci'), 14.104298433831065)\n",
      "(('puerto', 'rico'), 14.011189029439585)\n",
      "(('conan', 'doyle'), 13.981441686045535)\n",
      "(('\"joy', 'cooking\"'), 13.782370338943704)\n",
      "(('steven', 'spielberg'), 13.596151530160743)\n",
      "(('bruce', 'willis'), 13.42622652871843)\n",
      "(('ronald', 'reagan'), 13.32936498946584)\n",
      "(('debbie', 'reynolds'), 13.274223435273381)\n",
      "(('babe', 'ruth'), 13.256301527276118)\n",
      "(('heavyweight', 'boxing'), 13.077826222469875)\n",
      "(('warner', 'bros.'), 13.077826222469875)\n",
      "(('los', 'angeles'), 13.026295921829792)\n",
      "(('eddie', 'murphy'), 12.841264027997273)\n",
      "(('fairy', 'godmother'), 12.689260934552223)\n",
      "(('\"star', 'wars\"'), 12.677288292886146)\n",
      "(('\"star', 'trek\"'), 12.592399395299633)\n",
      "(('\"happy', 'days\"'), 12.573783717132287)\n",
      "(('\"tonight', 'show\"'), 12.487627073382573)\n",
      "(('martin', 'luther'), 12.367332839664861)\n",
      "(('las', 'vegas'), 12.367332839664858)\n",
      "(('tonight', 'show\"'), 12.265234652046125)\n",
      "(('woody', 'allen'), 12.211213637747578)\n",
      "(('nursery', 'rhyme,'), 12.174687761722463)\n",
      "(('nursery', 'rhyme'), 12.077826222469875)\n",
      "(('patron', 'saint'), 12.05022176107527)\n",
      "(('jimmy', 'stewart'), 12.03390910593967)\n",
      "(('jimmy', 'carter'), 12.007436894578479)\n",
      "(('active', 'volcano'), 11.988821216411132)\n",
      "(('ivy', 'league'), 11.95229534038602)\n",
      "(('stephen', 'crane'), 11.923726188189248)\n",
      "(('grand', 'slam'), 11.881906012494618)\n",
      "(('washington,', 'd.c.'), 11.85389163632502)\n",
      "(('super', 'bowl'), 11.739301617051815)\n",
      "(('degrees', 'fahrenheit'), 11.641955219773866)\n",
      "(('monetary', 'unit'), 11.618871606660825)\n",
      "(('al', 'gore'), 11.573783717132288)\n",
      "(('johnny', 'cash'), 11.573783717132288)\n",
      "(('declaration', 'independence'), 11.554492378523527)\n",
      "(('yellow', 'brick'), 11.551757410802288)\n",
      "(('golden', 'gate'), 11.537257841107174)\n",
      "(('peanut', 'butter'), 11.528269057879918)\n",
      "(('prime', 'minister'), 11.51417422799413)\n"
     ]
    }
   ],
   "source": [
    "#list the top 50 low-value bigrams by their Mutual Information scores (using min frequency 5)\n",
    "\n",
    "#score by PMI metric, filtering to be sure the bigrams appear at least 5 times\n",
    "qfinderlow.apply_freq_filter(5)\n",
    "lowqpmi = qfinderlow.score_ngrams(bgmeasures.pmi)\n",
    "\n",
    "for bigram in lowqpmi[:50]:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('agatha', 'christie'), 14.655426903131012)\n",
      "(('e.m.', 'forster'), 14.655426903131012)\n",
      "(('los', 'angeles'), 14.655426903131012)\n",
      "(('\"gone', 'wind\"'), 14.39239249729722)\n",
      "(('midsummer', \"night's\"), 14.292856823746305)\n",
      "(('nicolas', 'cage'), 14.240389403852166)\n",
      "(('clint', 'eastwood'), 14.140853730301252)\n",
      "(('h.g.', 'wells'), 14.140853730301252)\n",
      "(('ralph', 'waldo'), 13.87781932446746)\n",
      "(('edgar', 'allan'), 13.72581623102241)\n",
      "(('sherlock', 'holmes'), 13.655426903131012)\n",
      "(('t.s.', 'eliot'), 13.655426903131012)\n",
      "(('hong', 'kong'), 13.614784918633667)\n",
      "((\"night's\", 'dream\"'), 13.292856823746302)\n",
      "(('headquarters', 'tokyo,'), 13.276915279877283)\n",
      "(('spinal', 'cord'), 13.26638461238511)\n",
      "(('julius', 'caesar'), 13.240389403852168)\n",
      "(('teddy', 'roosevelt'), 13.225742627887765)\n",
      "(('allan', 'poe'), 13.199747419354823)\n",
      "(('h.w.', 'bush'), 13.112284578104484)\n",
      "(('eugene', \"o'neill\"), 13.044929310302718)\n",
      "(('en', 'route'), 12.887872989131383)\n",
      "(('julia', 'roberts'), 12.740315800717525)\n",
      "(('las', 'vegas'), 12.555891229580098)\n",
      "(('homeland', 'security'), 12.462781825188618)\n",
      "(('double):', '\"(hi,'), 12.418387705830163)\n",
      "(('super', 'bowl'), 12.352357835494965)\n",
      "(('sony', 'headquarters'), 12.276915279877283)\n",
      "((\"earth's\", 'crust'), 12.233963134692736)\n",
      "(('woody', 'allen'), 12.233963134692734)\n",
      "(('lewis', 'carroll'), 12.140853730301256)\n",
      "(('martial', 'arts'), 12.112284578104484)\n",
      "(('coat', 'arms'), 12.062851218299977)\n",
      "(('ivy', 'league'), 12.036517070486518)\n",
      "(('fits', 'category'), 11.887872989131383)\n",
      "(('(video', 'daily'), 11.818925635413892)\n",
      "(('(audio', 'daily'), 11.81892563541389)\n",
      "(('daily', 'double):'), 11.81892563541389)\n",
      "(('marine', 'corps'), 11.814809526941659)\n",
      "(('coen', 'brothers'), 11.810705128608923)\n",
      "(('f.', 'scott'), 11.778283650916544)\n",
      "(('anatomical', 'animation'), 11.769294867689291)\n",
      "(('periodic', 'table'), 11.687262990253014)\n",
      "(('gold', 'medalist'), 11.681422111663956)\n",
      "(('string', 'quartet'), 11.629891811023874)\n",
      "(('jimmy', 'carter'), 11.555891229580098)\n",
      "(('san', 'francisco,'), 11.555891229580096)\n",
      "(('plane', 'crash'), 11.51524924508275)\n",
      "(('fit', 'category'), 11.482234187854788)\n",
      "(('running', 'mate'), 11.451554569765362)\n"
     ]
    }
   ],
   "source": [
    "#list the top 50 high-value bigrams by their Mutual Information scores (using min frequency 5)\n",
    "\n",
    "#score by PMI metric, filtering to be sure the bigrams appear at least 5 times\n",
    "qfinderhigh.apply_freq_filter(5)\n",
    "highqpmi = qfinderhigh.score_ngrams(bgmeasures.pmi)\n",
    "\n",
    "for bigram in highqpmi[:50]:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('new', 'york', 'city'), 0.00017033518178549123)\n",
      "(('became', 'first', 'woman'), 8.832194611099545e-05)\n",
      "(('world', 'war', 'ii'), 6.939581480149642e-05)\n",
      "(('whose', 'name', 'means'), 6.308710436499675e-05)\n",
      "(('british', 'prime', 'minister'), 4.4160973055497726e-05)\n",
      "(('nobel', 'peace', 'prize'), 4.4160973055497726e-05)\n",
      "(('feet', 'sea', 'level'), 3.1543552182498374e-05)\n",
      "(('gave', 'us', 'name'), 3.1543552182498374e-05)\n",
      "(('john', 'f.', 'kennedy'), 3.1543552182498374e-05)\n",
      "(('john', 'paul', 'ii'), 3.1543552182498374e-05)\n",
      "(('north', 'american', 'country'), 3.1543552182498374e-05)\n",
      "(('real', 'first', 'name'), 3.1543552182498374e-05)\n",
      "(('talk', 'show', 'host'), 3.1543552182498374e-05)\n",
      "(('top', '40', 'hit'), 3.1543552182498374e-05)\n",
      "(('world', 'war', 'i,'), 3.1543552182498374e-05)\n",
      "(('\"monday', 'night', 'football\"'), 2.52348417459987e-05)\n",
      "(('\"saturday', 'night', 'fever\"'), 2.52348417459987e-05)\n",
      "(('american', 'red', 'cross'), 2.52348417459987e-05)\n",
      "(('arthur', 'conan', 'doyle'), 2.52348417459987e-05)\n",
      "(('became', 'first', 'black'), 2.52348417459987e-05)\n",
      "(('became', 'first', 'u.s.'), 2.52348417459987e-05)\n",
      "(('celebrated', '50th', 'anniversary'), 2.52348417459987e-05)\n",
      "(('e', 'street', 'band'), 2.52348417459987e-05)\n",
      "(('francis', 'ford', 'coppola'), 2.52348417459987e-05)\n",
      "(('future', 'first', 'lady'), 2.52348417459987e-05)\n",
      "(('ice', 'cream', 'flavor'), 2.52348417459987e-05)\n",
      "(('ivy', 'league', 'school'), 2.52348417459987e-05)\n",
      "(('july', '4,', '1826'), 2.52348417459987e-05)\n",
      "(('late', '19th', 'century'), 2.52348417459987e-05)\n",
      "(('league', 'baseball', 'team'), 2.52348417459987e-05)\n",
      "(('made', 'first', 'appearance'), 2.52348417459987e-05)\n",
      "(('major', 'league', 'baseball'), 2.52348417459987e-05)\n",
      "(('mayor', 'new', 'york'), 2.52348417459987e-05)\n",
      "(('new', 'south', 'wales'), 2.52348417459987e-05)\n",
      "(('new', \"year's\", 'eve'), 2.52348417459987e-05)\n",
      "(('new', 'york', 'city,'), 2.52348417459987e-05)\n",
      "(('president', 'united', 'states'), 2.52348417459987e-05)\n",
      "(('sir', 'arthur', 'conan'), 2.52348417459987e-05)\n",
      "(('st.', \"patrick's\", 'day'), 2.52348417459987e-05)\n",
      "(('world', 'war', 'ii,'), 2.52348417459987e-05)\n",
      "(('\"a', 'midsummer', \"night's\"), 1.8926131309499025e-05)\n",
      "(('\"as', 'good', 'gets\"'), 1.8926131309499025e-05)\n",
      "(('\"beautiful', 'blue\"', 'river'), 1.8926131309499025e-05)\n",
      "(('\"blond', 'ambition\"', 'tour'), 1.8926131309499025e-05)\n",
      "(('\"goodbye', 'yellow', 'brick'), 1.8926131309499025e-05)\n",
      "(('\"i', 'love', 'lucy\"'), 1.8926131309499025e-05)\n",
      "(('\"joy', 'cooking\"', 'says'), 1.8926131309499025e-05)\n",
      "(('\"little', 'women\"', 'author'), 1.8926131309499025e-05)\n",
      "(('\"my', 'heart', 'go'), 1.8926131309499025e-05)\n",
      "(('\"saturday', 'night', 'live\"'), 1.8926131309499025e-05)\n"
     ]
    }
   ],
   "source": [
    "#list the top 50 low-value trigrams by frequencies\n",
    "\n",
    "#create shorthand for full measures function\n",
    "trimeasures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "trifinderlow = TrigramCollocationFinder.from_words(lowtokens)\n",
    "triscoredlow = trifinderlow.score_ngrams(trimeasures.raw_freq)\n",
    "\n",
    "for trigram in triscoredlow[:50]:\n",
    "    print(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('whose', 'name', 'means'), 0.00013285873241697713)\n",
      "(('(video', 'daily', 'double):'), 0.00011625139086485499)\n",
      "(('world', 'war', 'ii'), 9.41082687953588e-05)\n",
      "(('new', 'york', 'city'), 8.303670776061071e-05)\n",
      "(('(audio', 'daily', 'double):'), 6.642936620848857e-05)\n",
      "(('nobel', 'peace', 'prize'), 4.9822024656366424e-05)\n",
      "(('whose', 'name', 'comes'), 4.9822024656366424e-05)\n",
      "(('\"a', 'midsummer', \"night's\"), 4.428624413899238e-05)\n",
      "(('early', '20th', 'century'), 4.428624413899238e-05)\n",
      "(('shows', 'anatomical', 'animation'), 4.428624413899238e-05)\n",
      "(('name', 'comes', 'latin'), 3.875046362161833e-05)\n",
      "(('south', 'american', 'country'), 3.875046362161833e-05)\n",
      "(('world', 'war', 'ii,'), 3.875046362161833e-05)\n",
      "(('became', 'first', 'woman'), 3.321468310424428e-05)\n",
      "(('chief', 'justice', 'u.s.'), 3.321468310424428e-05)\n",
      "(('civil', 'rights', 'leader'), 3.321468310424428e-05)\n",
      "(('comes', 'greek', 'words'), 3.321468310424428e-05)\n",
      "(('comes', 'latin', 'word'), 3.321468310424428e-05)\n",
      "(('comes', 'word', 'meaning'), 3.321468310424428e-05)\n",
      "(('daily', 'double):', '\"(hi,'), 3.321468310424428e-05)\n",
      "(('double):', '\"(hi,', \"i'm\"), 3.321468310424428e-05)\n",
      "(('gave', 'us', 'word'), 3.321468310424428e-05)\n",
      "(('midsummer', \"night's\", 'dream\"'), 3.321468310424428e-05)\n",
      "(('new', 'york', 'state'), 3.321468310424428e-05)\n",
      "(('new', 'york', 'times'), 3.321468310424428e-05)\n",
      "(('real', 'first', 'name'), 3.321468310424428e-05)\n",
      "(('supreme', 'court', 'justice'), 3.321468310424428e-05)\n",
      "(('air', 'force', 'base'), 2.7678902586870236e-05)\n",
      "(('became', 'first', 'black'), 2.7678902586870236e-05)\n",
      "(('best', 'picture', 'oscar'), 2.7678902586870236e-05)\n",
      "(('central', 'american', 'country'), 2.7678902586870236e-05)\n",
      "(('edgar', 'allan', 'poe'), 2.7678902586870236e-05)\n",
      "(('george', 'h.w.', 'bush'), 2.7678902586870236e-05)\n",
      "(('grand', 'central', 'terminal'), 2.7678902586870236e-05)\n",
      "(('major', 'league', 'baseball'), 2.7678902586870236e-05)\n",
      "(('million', 'years', 'ago'), 2.7678902586870236e-05)\n",
      "(('named', '19th', 'century'), 2.7678902586870236e-05)\n",
      "(('nobel', 'prize', 'literature'), 2.7678902586870236e-05)\n",
      "(('north', 'carolina', 'state'), 2.7678902586870236e-05)\n",
      "(('sony', 'headquarters', 'tokyo,'), 2.7678902586870236e-05)\n",
      "(('whose', 'work', 'seen'), 2.7678902586870236e-05)\n",
      "(('word', 'meaning', '\"to'), 2.7678902586870236e-05)\n",
      "(('19th', 'century', 'french'), 2.214312206949619e-05)\n",
      "(('5th', 'century', 'b.c.'), 2.214312206949619e-05)\n",
      "(('add', 'letter', 'country'), 2.214312206949619e-05)\n",
      "(('arthur', 'miller', 'play'), 2.214312206949619e-05)\n",
      "(('aung', 'san', 'suu'), 2.214312206949619e-05)\n",
      "(('became', 'first', 'man'), 2.214312206949619e-05)\n",
      "(('comes', 'words', 'meaning'), 2.214312206949619e-05)\n",
      "(('daphne', 'du', 'maurier'), 2.214312206949619e-05)\n"
     ]
    }
   ],
   "source": [
    "#list the top 50 high-value trigrams by frequencies\n",
    "\n",
    "trifinderhigh = TrigramCollocationFinder.from_words(hightokens)\n",
    "triscoredhigh = trifinderhigh.score_ngrams(trimeasures.raw_freq)\n",
    "\n",
    "for trigram in triscoredhigh[:50]:\n",
    "    print(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
